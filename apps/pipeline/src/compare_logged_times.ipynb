{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking of runtimes for the various modules\n",
    "This notebook is used to benchmark the runtimes of the various modules in the Sapphire system. It is based on the task_timings.log files generated by the SAPPHIRE Forecast Tools.\n",
    "\n",
    "### How to get the data\n",
    "Copy the task_timings.log files from the Zurich and the Kyrgyz hydromet servers. \n",
    "\n",
    "#### Zurich-based AWS server\n",
    "```bash\n",
    "scp -i \"internal_sapphire_forecast_zurich.pem\" ubuntu@ec2-51-96-139-196.eu-central-2.compute.amazonaws.com:/data/sensitive_data_forecast_tools/intermediate_data/task_timings.log ../intermediate_data/task_timings_ZH_20250424.log\n",
    "```\n",
    "\n",
    "#### Kygrys Hydromet server\n",
    "```bash\n",
    "scp -P 5807 sapphire@212.112.125.69:/data/sensitive_data_forecast_tools/intermediate_data/task_timings.log .\n",
    "```\n",
    "Then move the file to the intermediate_data directory and rename it with _KG_<date> suffix analogue to the name above. \n",
    "\n",
    "#### Adapt paths in script below\n",
    "Then adapt the file names in the script below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to parse the log file\n",
    "def parse_timing_log(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Split by separator line\n",
    "    entries = content.split('--------------------------------------------------')\n",
    "\n",
    "    # Parse each entry\n",
    "    data = []\n",
    "    for entry in entries:\n",
    "        if not entry.strip():\n",
    "            continue\n",
    "\n",
    "        task_match = re.search(r'Task: (.*?)$', entry, re.MULTILINE)\n",
    "        start_match = re.search(r'Start Time: (.*?)$', entry, re.MULTILINE)\n",
    "        end_match = re.search(r'End Time: (.*?)$', entry, re.MULTILINE)\n",
    "        duration_match = re.search(r'Duration: (.*?) seconds', entry, re.MULTILINE)\n",
    "        status_match = re.search(r'Status: (.*?)$', entry, re.MULTILINE)\n",
    "        details_match = re.search(r'Details: (.*?)$', entry, re.MULTILINE)\n",
    "\n",
    "        if all([task_match, start_match, end_match, duration_match, status_match]):\n",
    "            task = task_match.group(1).strip()\n",
    "            start_time = start_match.group(1).strip()\n",
    "            end_time = end_match.group(1).strip()\n",
    "            duration = float(duration_match.group(1).strip())\n",
    "            status = status_match.group(1).strip()\n",
    "            details = details_match.group(1).strip() if details_match else ''\n",
    "\n",
    "            data.append({\n",
    "                'Task': task,\n",
    "                'Start Time': datetime.fromisoformat(start_time),\n",
    "                'End Time': datetime.fromisoformat(end_time),\n",
    "                'Duration': duration,\n",
    "                'Status': status,\n",
    "                'Details': details\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Define paths to both log files\n",
    "base_path = sys.path[0] + '/../../../../sensitive_data_forecast_tools/intermediate_data/'\n",
    "kg_file_path = os.path.abspath(base_path + 'task_timings_KG_20250424.log')\n",
    "zh_file_path = os.path.abspath(base_path + 'task_timings_ZH_20250424.log')\n",
    "\n",
    "# Parse both log files\n",
    "df_kg = parse_timing_log(kg_file_path)\n",
    "df_zh = parse_timing_log(zh_file_path)\n",
    "\n",
    "# Add location identifier\n",
    "df_kg['Location'] = 'Kyrgyzstan'\n",
    "df_zh['Location'] = 'Zurich'\n",
    "\n",
    "# Get the latest entry for each task from both locations\n",
    "latest_kg = df_kg.sort_values('End Time').groupby('Task').last().reset_index()\n",
    "latest_zh = df_zh.sort_values('End Time').groupby('Task').last().reset_index()\n",
    "\n",
    "# Combine the datasets\n",
    "comparison = pd.merge(\n",
    "    latest_kg[['Task', 'Duration', 'Start Time', 'End Time']],\n",
    "    latest_zh[['Task', 'Duration', 'Start Time', 'End Time']],\n",
    "    on='Task',\n",
    "    suffixes=('_KG', '_ZH')\n",
    ")\n",
    "\n",
    "# Calculate the difference and ratio\n",
    "comparison['Duration_Diff_KG_ZH'] = comparison['Duration_KG'] - comparison['Duration_ZH']\n",
    "comparison['Duration_Ratio_KG_ZH'] = comparison['Duration_KG'] / comparison['Duration_ZH']\n",
    "comparison['Time_Between_Runs'] = (comparison['Start Time_KG'] - comparison['Start Time_ZH']).dt.total_seconds() / 3600  # in hours\n",
    "\n",
    "# Sort by the absolute difference\n",
    "comparison = comparison.sort_values('Duration_Diff_KG_ZH', key=abs, ascending=False)\n",
    "\n",
    "# Display the comparison\n",
    "print(\"Task Timing Comparison (Latest Run per Task) - KG vs ZH:\")\n",
    "print(comparison[['Task', 'Duration_KG', 'Duration_ZH', 'Duration_Diff_KG_ZH', 'Duration_Ratio_KG_ZH']])\n",
    "\n",
    "# Create a combined dataframe for plotting\n",
    "plot_data = pd.DataFrame({\n",
    "    'Task': comparison['Task'],\n",
    "    'Kyrgyzstan': comparison['Duration_KG'],\n",
    "    'Zurich': comparison['Duration_ZH']\n",
    "})\n",
    "\n",
    "# Reshape for seaborn\n",
    "plot_data_melted = pd.melt(plot_data, id_vars=['Task'], var_name='Location', value_name='Duration')\n",
    "\n",
    "# Bar plot comparing durations\n",
    "plt.figure(figsize=(14, 10))\n",
    "ax = sns.barplot(x='Duration', y='Task', hue='Location', data=plot_data_melted)\n",
    "plt.title('Task Duration Comparison: Kyrgyzstan vs. Zurich (Latest Run)', fontsize=14)\n",
    "plt.xlabel('Duration (seconds)', fontsize=12)\n",
    "plt.ylabel('Task', fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Ratio plot (KG/ZH)\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.barh(comparison['Task'], comparison['Duration_Ratio_KG_ZH'], color=np.where(comparison['Duration_Ratio_KG_ZH'] > 1, 'red', 'green'))\n",
    "plt.axvline(x=1, color='black', linestyle='--')\n",
    "plt.title('Task Duration Ratio: Kyrgyzstan / Zurich', fontsize=14)\n",
    "plt.xlabel('Duration Ratio (KG/ZH)', fontsize=12)\n",
    "plt.ylabel('Task', fontsize=12)\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add text labels with actual values\n",
    "for i, bar in enumerate(bars):\n",
    "    ratio = comparison['Duration_Ratio_KG_ZH'].iloc[i]\n",
    "    if ratio > 10:\n",
    "        # Position for extremely large values\n",
    "        plt.text(10, bar.get_y() + bar.get_height()/2, f\"{ratio:.1f}x\", va='center', fontsize=9, color='red')\n",
    "    elif ratio > 1:\n",
    "        plt.text(ratio - 0.5, bar.get_y() + bar.get_height()/2, f\"{ratio:.1f}x\", va='center', fontsize=9)\n",
    "    else:\n",
    "        plt.text(ratio + 0.1, bar.get_y() + bar.get_height()/2, f\"{ratio:.1f}x\", va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Create scatter plot to see correlation between task durations\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(comparison['Duration_ZH'], comparison['Duration_KG'], alpha=0.7)\n",
    "\n",
    "# Add reference line (y=x)\n",
    "max_val = max(comparison['Duration_KG'].max(), comparison['Duration_ZH'].max())\n",
    "plt.plot([0, max_val], [0, max_val], 'k--', alpha=0.5)\n",
    "\n",
    "# Add task labels\n",
    "for i, txt in enumerate(comparison['Task']):\n",
    "    plt.annotate(txt, (comparison['Duration_ZH'].iloc[i], comparison['Duration_KG'].iloc[i]),\n",
    "                fontsize=8, alpha=0.8)\n",
    "\n",
    "plt.title('Task Duration Correlation: Kyrgyzstan vs. Zurich', fontsize=14)\n",
    "plt.xlabel('Zurich Duration (seconds)', fontsize=12)\n",
    "plt.ylabel('Kyrgyzstan Duration (seconds)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Identify the tasks with the most significant slowdowns in Kyrgyzstan\n",
    "print(\"\\nTasks with Greatest Slowdown in Kyrgyzstan:\")\n",
    "slowdowns = comparison.sort_values('Duration_Ratio_KG_ZH', ascending=False)\n",
    "print(slowdowns[slowdowns['Duration_Ratio_KG_ZH'] > 1][['Task', 'Duration_KG', 'Duration_ZH', 'Duration_Ratio_KG_ZH']].head(5))\n",
    "\n",
    "# Calculate total pipeline time comparison\n",
    "kg_pipeline_time = latest_kg['Duration'].sum()\n",
    "zh_pipeline_time = latest_zh['Duration'].sum()\n",
    "print(f\"\\nTotal Pipeline Duration Comparison:\")\n",
    "print(f\"Kyrgyzstan: {kg_pipeline_time:.1f} seconds ({kg_pipeline_time/60:.1f} minutes)\")\n",
    "print(f\"Zurich: {zh_pipeline_time:.1f} seconds ({zh_pipeline_time/60:.1f} minutes)\")\n",
    "print(f\"Difference: {kg_pipeline_time - zh_pipeline_time:.1f} seconds ({(kg_pipeline_time - zh_pipeline_time)/60:.1f} minutes)\")\n",
    "print(f\"Ratio: {kg_pipeline_time / zh_pipeline_time:.2f}x\")\n",
    "\n",
    "# Time of day analysis\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_kg['Start Time'].dt.hour, bins=24, kde=True, color='blue')\n",
    "plt.title('Kyrgyzstan Task Start Times')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.xticks(range(0, 24, 2))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df_zh['Start Time'].dt.hour, bins=24, kde=True, color='green')\n",
    "plt.title('Zurich Task Start Times')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.xticks(range(0, 24, 2))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plots\n",
    "plt.show()\n",
    "\n",
    "# Export the comparison to CSV\n",
    "#comparison.to_csv('kg_zh_task_comparison.csv', index=False)\n",
    "#print(\"\\nComparison data saved to kg_zh_task_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsol_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
